{"cells":[{"cell_type":"markdown","id":"cFfY5IwzYhE3","metadata":{"id":"cFfY5IwzYhE3"},"source":["| | |\n","|:---:|:---|\n","| <img src=\"https://i.ytimg.com/vi/1W-sWmFQPZY/sddefault.jpg\" width=\"200\"/> |  <strong><font size=5>Future x Summer School 2025 </font></strong><br><br><strong><font color=\"#1A54A6\" size=5>LLMs<br>Lab 2 Part A: Embeddings in Context (DEMO)</font></strong>|\n","\n","---\n","\n","\n","\n","**Instructor:**  \n","Pavlos Protopapas  \n","\n","**Teaching Team:**  \n","Nawang Thinley Bhutia\n","\n"]},{"cell_type":"markdown","id":"7jrBr1SwxqLb","metadata":{"id":"7jrBr1SwxqLb"},"source":["\n","In this notebook, we will explore how context can impact embeddings. We first use word2vec and oserve **static embeddings** and then assess how using a model like BERT (Bidirectional Encoder Representations from Transformers) can give us enhanced **contextualised embeddings**."]},{"cell_type":"markdown","id":"gMd8pUwSYWrv","metadata":{"id":"gMd8pUwSYWrv"},"source":["**üìù Make a Copy to Edit**\n","\n","This notebook is **view-only**. To edit it, follow these steps:\n","\n","1. Click **File** > **Save a copy in Drive**.\n","2. Your own editable copy will open in a new tab.\n","\n","Now you can modify and run the code freely!"]},{"cell_type":"markdown","id":"71d7c253","metadata":{"id":"71d7c253"},"source":["\n","\n","## Table of Contents\n"," **Part A**\n","\n","\n","- <font color ='#CE6DFF'>**Using Word2Vec**</font>\n","    -   Extracting relevant embeddings\n","    -   Applying dimensionality reduction\n","    -   Exploring word embeddings\n","-<font color ='#34B086'>**Using BERT**</font>\n","    -   Extracting relevant embeddings\n","    -   Applying dimensionality reduction\n","    -   Exploring word embeddings\n","\n","- <font color ='1A54A6'>**Take Home Exercise**üè°\n","\n","\n","---\n","\n"]},{"cell_type":"markdown","id":"NrFd4tvYgFPC","metadata":{"id":"NrFd4tvYgFPC"},"source":["## **Importing the require libraries**"]},{"cell_type":"code","execution_count":1,"id":"yLSIpnCVHCTg","metadata":{"id":"yLSIpnCVHCTg","executionInfo":{"status":"ok","timestamp":1753532840721,"user_tz":-480,"elapsed":13577,"user":{"displayName":"È°æÊòäÁëú","userId":"08614030970622153399"}}},"outputs":[],"source":["pip install -q sentence-transformers"]},{"cell_type":"code","source":["!pip install gensim"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mIWCFd5x1s9H","executionInfo":{"status":"ok","timestamp":1753532853184,"user_tz":-480,"elapsed":12468,"user":{"displayName":"È°æÊòäÁëú","userId":"08614030970622153399"}},"outputId":"cb3947e4-0b9a-48e8-d3a8-489f47ec4503"},"id":"mIWCFd5x1s9H","execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: gensim in /usr/local/lib/python3.11/dist-packages (4.3.3)\n","Requirement already satisfied: numpy<2.0,>=1.18.5 in /usr/local/lib/python3.11/dist-packages (from gensim) (1.26.4)\n","Requirement already satisfied: scipy<1.14.0,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from gensim) (1.13.1)\n","Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.11/dist-packages (from gensim) (7.3.0.post1)\n","Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from smart-open>=1.8.1->gensim) (1.17.2)\n"]}]},{"cell_type":"code","execution_count":3,"id":"QzdzOquQgg76","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7748,"status":"ok","timestamp":1753532860933,"user":{"displayName":"È°æÊòäÁëú","userId":"08614030970622153399"},"user_tz":-480},"id":"QzdzOquQgg76","outputId":"abe504a5-e65d-4ef7-e387-211cac58834a"},"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/stopwords.zip.\n"]}],"source":["import numpy as np\n","\n","#for dimensionality reduction\n","from sklearn.decomposition import PCA\n","\n","#for plotting\n","import matplotlib.pyplot as plt\n","import plotly.express as px\n","import plotly.graph_objects as go\n","#from plotly.subplots import make_subplots\n","\n","\n","#for text preprocessing\n","import nltk\n","nltk.download('stopwords')\n","from nltk.corpus import stopwords"]},{"cell_type":"markdown","id":"g-3R6ESyYSwe","metadata":{"id":"g-3R6ESyYSwe"},"source":["## **Sample Sentences**"]},{"cell_type":"code","execution_count":4,"id":"OJvCV-HQc9qy","metadata":{"id":"OJvCV-HQc9qy","executionInfo":{"status":"ok","timestamp":1753532860939,"user_tz":-480,"elapsed":3,"user":{"displayName":"È°æÊòäÁëú","userId":"08614030970622153399"}}},"outputs":[],"source":["sentences = [\n","    \"I am going to the bank to withdraw money\",\n","    \"He is sitting on the river bank\",\n","    \"She went to the bank to deposit a check\",\n","    \"They had a picnic by the river bank\",\n","    \"I need to withdraw cash from the bank\",\n","    \"The kids are playing on the river bank\"\n","]"]},{"cell_type":"code","execution_count":5,"id":"ExRIEy6pcyOn","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5,"status":"ok","timestamp":1753532860946,"user":{"displayName":"È°æÊòäÁëú","userId":"08614030970622153399"},"user_tz":-480},"id":"ExRIEy6pcyOn","outputId":"352d3d01-e3ff-4d99-9dfc-38e88363d9fe"},"outputs":[{"output_type":"stream","name":"stdout","text":["['going', 'bank', 'withdraw', 'money', 'sitting', 'river', 'bank', 'went', 'bank', 'deposit', 'check', 'picnic', 'river', 'bank', 'need', 'withdraw', 'cash', 'bank', 'kids', 'playing', 'river', 'bank']\n"]}],"source":["#remember your preprocessing steps from lab 1\n","stop_words = set(stopwords.words('english')) #these are typical stop words in english like a, an , the\n","\n","#lets see what words remain once we remove stopwords\n","words_of_interest = [word for sentence in sentences for word in sentence.lower().split() if word not in stop_words]\n","print(words_of_interest)"]},{"cell_type":"markdown","id":"eyUT_kgt2zay","metadata":{"id":"eyUT_kgt2zay"},"source":["\n","# <font color ='#CE6DFF'>**Using Word2Vec**</font>"]},{"cell_type":"markdown","id":"f7JcwdSZ_G_L","metadata":{"id":"f7JcwdSZ_G_L"},"source":["## **Loading pretrained word2vec model**\n","\n","Just like we did for Lab 1 (PartB)!\n"]},{"cell_type":"code","execution_count":null,"id":"8IKNQCE8_KkP","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8IKNQCE8_KkP","outputId":"cb41aad7-590e-4861-e885-95c10348da39"},"outputs":[{"output_type":"stream","name":"stdout","text":["Model does not exist, loading model\n","[=====================-----------------------------] 43.2% 718.6/1662.8MB downloaded"]}],"source":["# Load pre-trained Word2Vec model (Google News vectors) using gensim downloader\n","# Note: This cell can take upto 10+ minutes to load the entire model\n","import gensim.downloader as api\n","if 'model_google_w2v' in locals():\n","  print(\"Model already exists, using existing model\")\n","else:\n","  print(\"Model does not exist, loading model\")\n","  model_google_w2v = api.load('word2vec-google-news-300')"]},{"cell_type":"markdown","id":"OXQZwbjRYfH4","metadata":{"id":"OXQZwbjRYfH4"},"source":["\n","## **Extract Embeddings for all words**"]},{"cell_type":"code","execution_count":null,"id":"YE6p5_TtG7nX","metadata":{"id":"YE6p5_TtG7nX"},"outputs":[],"source":["## Collect only the words present in the model and their vectors\n","word_vector_pairs = [(word, model_google_w2v[word]) for word in words_of_interest if word in model_google_w2v]\n","word_vectors = np.array([pair[1] for pair in word_vector_pairs])"]},{"cell_type":"code","execution_count":null,"id":"1OHBMPa5PJXu","metadata":{"id":"1OHBMPa5PJXu"},"outputs":[],"source":["word_vectors.shape"]},{"cell_type":"markdown","id":"qhNPH83CAiOj","metadata":{"id":"qhNPH83CAiOj"},"source":["### **Dimensionality reduction**"]},{"cell_type":"code","execution_count":null,"id":"T9DBW35-dxHQ","metadata":{"id":"T9DBW35-dxHQ"},"outputs":[],"source":["# We use PCA for dimensionality reduction\n","pca = PCA(n_components=2)\n","embeddings_2d_pca = pca.fit_transform(word_vectors)"]},{"cell_type":"markdown","id":"Z4SFWjci_Usl","metadata":{"id":"Z4SFWjci_Usl"},"source":["## **Plot the Embeddings**"]},{"cell_type":"code","execution_count":null,"id":"UK7L09zqsSMj","metadata":{"id":"UK7L09zqsSMj"},"outputs":[],"source":["## Plot the Embeddings\n","plt.figure(figsize=(10, 10))\n","for i, (word, _) in enumerate(word_vector_pairs):\n","    plt.scatter(embeddings_2d_pca[i, 0], embeddings_2d_pca[i, 1], label=word)  # Plot each point individually\n","    plt.annotate(word, (embeddings_2d_pca[i, 0], embeddings_2d_pca[i, 1]), textcoords=\"offset points\", xytext=(0,10), ha='center')\n","plt.title('2D Visualization of Static Word Embeddings -PCA')\n","plt.xlabel('Component 1')\n","plt.ylabel('Component 2')\n","plt.grid(True)\n","plt.show()"]},{"cell_type":"markdown","id":"n_ojMwe0_3iF","metadata":{"id":"n_ojMwe0_3iF"},"source":["### We can see that there is only one embedding per word."]},{"cell_type":"markdown","id":"XCS0DiakiTQE","metadata":{"id":"XCS0DiakiTQE"},"source":["### However, overlapping points are not clear enough here so let us try plotly (another alternative to matplotlib)"]},{"cell_type":"code","execution_count":null,"id":"fadAPxcsiW-Z","metadata":{"id":"fadAPxcsiW-Z"},"outputs":[],"source":["## Create Plotly graph\n","fig = go.Figure()\n","\n","# Adding each point separately to include custom hover text\n","for i, (word, _) in enumerate(word_vector_pairs):\n","    fig.add_trace(go.Scatter(x=[embeddings_2d_pca[i, 0]], y=[embeddings_2d_pca[i, 1]],\n","                             mode='markers+text', text=[word], textposition='top center',\n","                             marker=dict(size=10, opacity=0.8),\n","                             name=word))  # Name sets the hover text\n","\n","fig.update_layout(title='2D Visualization of Static Word Embeddings using PCA',\n","                  xaxis_title='Component 1',\n","                  yaxis_title='Component 2',\n","                  width=1600,\n","                  height=900,\n","                  showlegend=False)  # Set to True if you want a legend\n","\n","fig.show()"]},{"cell_type":"markdown","id":"2ewsPTZGg0Kp","metadata":{"id":"2ewsPTZGg0Kp"},"source":["# <font color ='#34B086'>**Using BERT**</font>"]},{"cell_type":"markdown","id":"_-jRImzo4D5t","metadata":{"id":"_-jRImzo4D5t"},"source":["Now let us try to use BERT and compare our results"]},{"cell_type":"code","execution_count":null,"id":"492LSu55g4To","metadata":{"id":"492LSu55g4To"},"outputs":[],"source":["#using the transformers library\n","from transformers import BertTokenizer, TFBertModel\n","import tensorflow as tf"]},{"cell_type":"markdown","id":"v0oaQwVBhFHn","metadata":{"id":"v0oaQwVBhFHn"},"source":["### Generate Word Embeddings with BERT\n"]},{"cell_type":"code","execution_count":null,"id":"5yFYcgJwhBDz","metadata":{"id":"5yFYcgJwhBDz"},"outputs":[],"source":["# Load BERT Model and Tokenizer\n","tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n","model_bert = TFBertModel.from_pretrained('bert-base-uncased')"]},{"cell_type":"markdown","id":"iCMs8lMP70sJ","metadata":{"id":"iCMs8lMP70sJ"},"source":["##### (Note: You can safely ignore these warning we do not need a HF_TOKEN for our use case right now and we do not need extra weights as we are not training.)"]},{"cell_type":"markdown","id":"_AgMHJJ8hInK","metadata":{"id":"_AgMHJJ8hInK"},"source":["### Tokenize sentences and get embeddings"]},{"cell_type":"code","execution_count":null,"id":"hBroBnaJg42h","metadata":{"id":"hBroBnaJg42h"},"outputs":[],"source":["#let's create a function to get our embeddings\n","def get_bert_embeddings(sentences):\n","    inputs = tokenizer(sentences, return_tensors='tf', padding=True, truncation=True, max_length=128)\n","    outputs = model_bert(inputs)\n","    embeddings = outputs.last_hidden_state #these are the ebeddings!\n","    return embeddings"]},{"cell_type":"code","execution_count":null,"id":"QmJUNzOwhNdE","metadata":{"id":"QmJUNzOwhNdE"},"outputs":[],"source":["# Get embeddings for each token in the sentences\n","embeddings = get_bert_embeddings(sentences)"]},{"cell_type":"code","execution_count":null,"id":"kRC4UC0vhQW2","metadata":{"cellView":"form","id":"kRC4UC0vhQW2"},"outputs":[],"source":["#@title ###**Plotting 2D BERT embeings using matplotlib**\n","# Extract embeddings for each word\n","word_vectors = []\n","labels = []\n","colors = []\n","\n","# Define a color for each sentence\n","color_map = {\n","    0: 'r', 1: 'g', 2: 'b', 3: 'c', 4: 'm', 5: 'y'\n","}\n","\n","for i, sentence in enumerate(sentences):\n","    tokens = tokenizer.tokenize(sentence)\n","    for j, token in enumerate(tokens):\n","        word_vectors.append(embeddings[i][j].numpy())\n","        labels.append(token)\n","        colors.append(color_map[i])\n","\n","# Dimensionality Reduction\n","# Apply PCA\n","pca = PCA(n_components=2)\n","word_vectors_2d = pca.fit_transform(word_vectors)\n","\n","# Interactive Visualization\n","# Initialize Plot\n","plt.figure(figsize=(10, 7))\n","scatter_plots = []\n","unique_colors = set(colors)\n","for color in unique_colors:\n","    indices = [i for i, c in enumerate(colors) if c == color]\n","    scatter = plt.scatter(word_vectors_2d[indices, 0], word_vectors_2d[indices, 1], c=color, label=f\"Sentence {list(color_map.keys())[list(color_map.values()).index(color)] + 1}\")\n","    scatter_plots.append(scatter)\n","\n","# Add text labels for each word\n","for i, label in enumerate(labels):\n","    x, y = word_vectors_2d[i, :]\n","    plt.text(x + 0.03, y + 0.03, label, fontsize=9)\n","\n","# Create a legend\n","plt.legend(loc=\"best\")\n","\n","plt.title(\"2D BERT Contextualised Embeddings Visualization\")\n","plt.xlabel(\"PCA Component 1\")\n","plt.ylabel(\"PCA Component 2\")\n","\n","plt.show()"]},{"cell_type":"markdown","id":"RAdSp4r6jkpY","metadata":{"id":"RAdSp4r6jkpY"},"source":["### let's try plotly version to see overlapping points better"]},{"cell_type":"code","execution_count":null,"id":"WeToyFYKjkcD","metadata":{"cellView":"form","id":"WeToyFYKjkcD"},"outputs":[],"source":["#@title ###**Plotting 2D BERT embeings using plotly**\n","# Extract embeddings for each word\n","word_vectors = []\n","labels = []\n","colors = []\n","\n","# Define a color for each sentence\n","color_map = {\n","    0: 'red', 1: 'green', 2: 'blue', 3: 'cyan', 4: 'magenta', 5: 'yellow'\n","}\n","\n","for i, sentence in enumerate(sentences):\n","    tokens = tokenizer.tokenize(sentence)\n","    for j, token in enumerate(tokens):\n","        word_vectors.append(embeddings[i][j].numpy())\n","        labels.append(token)\n","        colors.append(color_map[i])  # Use the full color name here\n","\n","# Dimensionality Reduction\n","# Apply PCA\n","pca = PCA(n_components=2)\n","word_vectors_2d = pca.fit_transform(word_vectors)\n","\n","# Interactive Visualization\n","# Initialize Plotly figure\n","fig = go.Figure()\n","\n","# Add points for each token\n","for i, label in enumerate(labels):\n","    fig.add_trace(go.Scatter(\n","        x=[word_vectors_2d[i, 0]],\n","        y=[word_vectors_2d[i, 1]],\n","        mode='markers+text',\n","        name=label,\n","        text=[label],\n","        textposition='top center',\n","        marker=dict(color=colors[i])\n","    ))\n","\n","# Add buttons to toggle visibility of each sentence\n","buttons = []\n","for color in set(color_map.values()):  # Iterate over full color names\n","    indices = [i for i, c in enumerate(colors) if c == color]\n","    sentence_index = list(color_map.keys())[list(color_map.values()).index(color)]\n","    buttons.append(\n","        dict(\n","            label=f\"Sentence {sentence_index + 1}\",\n","            method=\"update\",\n","            args=[{\"visible\": [i in indices for i in range(len(labels))]}]\n","        )\n","    )\n","\n","# Add a button to show all\n","buttons.append(\n","    dict(\n","        label=\"Show All\",\n","        method=\"update\",\n","        args=[{\"visible\": [True] * len(labels)}]\n","    )\n",")\n","\n","# Add a button to hide all\n","buttons.append(\n","    dict(\n","        label=\"Hide All\",\n","        method=\"update\",\n","        args=[{\"visible\": [False] * len(labels)}]\n","    )\n",")\n","\n","# Update layout with buttons\n","fig.update_layout(\n","    title=\"2D BERT Contextualised Embeddings Visualization\",\n","    xaxis_title=\"PCA Component 1\",\n","    yaxis_title=\"PCA Component 2\",\n","    updatemenus=[dict(type=\"buttons\", showactive=True, buttons=buttons)]\n",")\n","\n","# Show plot\n","fig.show()"]},{"cell_type":"markdown","id":"ETSMBBTv4ah_","metadata":{"id":"ETSMBBTv4ah_"},"source":["### <font color ='#34B086'>**What do you notice from the plot above? How does *context* improve the embeddings?**</font>\n","\n","Pay close attention to the clusters that emerge. The word bank now has 3 embeddings near words like river and picnic and the other three near bank, check, cash etc."]},{"cell_type":"markdown","id":"Tx_-GLd26kTA","metadata":{"id":"Tx_-GLd26kTA"},"source":["### Here is a brief comparision of the two approaches we looked at:\n","\n","- **Embedding Type**:\n","  - **word2vec**: Static embeddings (single vector per word).\n","  - **BERT**: Contextualized embeddings (different vectors for the same word based on context).\n","\n","- **Model Architecture**:\n","  - **word2vec**: Shallow neural network.\n","  - **BERT**: Deep transformer architecture.\n","\n","- **Contextual Understanding**:\n","  - **word2vec**: Ignores context; words with multiple meanings have a single representation.\n","  - **BERT**: Incorporates context; words with multiple meanings have different representations based on their context.\n","\n","- **Training Objective**:\n","  - **word2vec**: Trained using Skip-gram or CBOW models to predict nearby words.\n","  - **BERT**: Trained using masked language modeling (MLM) and next sentence prediction (NSP).\n","\n","- **Directionality**:\n","  - **word2vec**: Processes words in one direction (context is limited to nearby words).\n","  - **BERT**: Bidirectional (considers the full sentence context, both before and after the target word).\n","\n","- **Performance on NLP Tasks**:\n","  - **word2vec**: Good for basic semantic similarity tasks.\n","  - **BERT**: Superior performance on a wide range of NLP tasks, including question answering and text classification.\n"]},{"cell_type":"markdown","id":"vtIeO24j3OrA","metadata":{"id":"vtIeO24j3OrA"},"source":["## <font color ='1A54A6'>**Take Home Exercise**üè°\n","\n","\n","Test this notebook with your own sentences where context impacts word meanings directly."]},{"cell_type":"markdown","id":"B6x6dzJ7NCpj","metadata":{"id":"B6x6dzJ7NCpj"},"source":["### **BONUS**:\n","Refer to [this](https://github.com/tensorflow/text/blob/master/docs/tutorials/word2vec.ipynb) official word2vec notebook from tensorflow or the BERT information page on HuggingFace [here](https://huggingface.co/docs/transformers/model_doc/bert#transformers.BertForMaskedLM.forward) for even more details. (not needed for this course)"]}],"metadata":{"colab":{"provenance":[{"file_id":"1e2drbESeDMVf1sQdEbxGsZPuwZqxO2W_","timestamp":1753510113761},{"file_id":"1mCKgn-5HhiNFwfbI3aRU244_2_xrZq3t","timestamp":1721655107209}]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.4"}},"nbformat":4,"nbformat_minor":5}