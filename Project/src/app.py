from flask import Flask, request, jsonify, render_template, send_file
from generator.documentation import DocumentationGenerator
import threading
import webbrowser
import time
import os
import zipfile
import socket
import signal
import sys
import requests
import tempfile
import shutil
from pathlib import Path
import re
from urllib.parse import urlparse

app = Flask(__name__)

# ä»ç¯å¢ƒå˜é‡æˆ–é…ç½®æ–‡ä»¶è·å–OpenAI APIå¯†é’¥
OPENAI_API_KEY = "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"

# åˆå§‹åŒ–æ–‡æ¡£ç”Ÿæˆå™¨
doc_generator = None
if OPENAI_API_KEY and OPENAI_API_KEY != "your-api-key-here":
    doc_generator = DocumentationGenerator(OPENAI_API_KEY)

# æ”¯æŒçš„ä»£ç æ–‡ä»¶æ‰©å±•å
SUPPORTED_EXTENSIONS = {'.py', '.js', '.ts', '.java', '.cpp', '.c', '.cs', '.php', '.rb', 
                       '.go', '.rs', '.swift', '.kt', '.scala', '.r', '.m', '.pl', 
                       '.sh', '.sql', '.html', '.css', '.vue', '.jsx', '.tsx'}

def find_free_port(start_port=9003, max_attempts=10):
    """æŸ¥æ‰¾å¯ç”¨ç«¯å£"""
    for port in range(start_port, start_port + max_attempts):
        try:
            with socket.socket(socket.AF_INET, socket.SOCK_STREAM) as s:
                s.bind(('localhost', port))
                return port
        except OSError:
            continue
    raise Exception(f"æ— æ³•æ‰¾åˆ°å¯ç”¨ç«¯å£ï¼Œä» {start_port} åˆ° {start_port + max_attempts - 1} éƒ½è¢«å ç”¨")

def kill_port_process(port):
    """å°è¯•æ€æ­»å ç”¨æŒ‡å®šç«¯å£çš„è¿›ç¨‹"""
    try:
        import subprocess
        import platform
        
        system = platform.system()
        if system == "Darwin" or system == "Linux":  # macOS or Linux
            try:
                # æŸ¥æ‰¾å ç”¨ç«¯å£çš„è¿›ç¨‹ID
                result = subprocess.run(['lsof', '-ti', f':{port}'], 
                                      capture_output=True, text=True)
                if result.stdout.strip():
                    pids = result.stdout.strip().split('\n')
                    for pid in pids:
                        subprocess.run(['kill', '-9', pid], check=True)
                    print(f"âœ… å·²æ¸…ç†ç«¯å£ {port} ä¸Šçš„è¿›ç¨‹")
                    time.sleep(1)  # ç­‰å¾…ç«¯å£é‡Šæ”¾
                    return True
            except subprocess.CalledProcessError:
                pass
        elif system == "Windows":
            try:
                # Windowsç«¯å£æ¸…ç†
                result = subprocess.run(['netstat', '-ano'], capture_output=True, text=True)
                lines = result.stdout.split('\n')
                for line in lines:
                    if f':{port}' in line and 'LISTENING' in line:
                        parts = line.split()
                        if len(parts) > 4:
                            pid = parts[-1]
                            subprocess.run(['taskkill', '/PID', pid, '/F'], check=True)
                            print(f"âœ… å·²æ¸…ç†ç«¯å£ {port} ä¸Šçš„è¿›ç¨‹")
                            time.sleep(1)
                            return True
            except subprocess.CalledProcessError:
                pass
    except ImportError:
        pass
    return False

def signal_handler(sig, frame):
    """ä¼˜é›…åœ°å¤„ç†Ctrl+Cä¿¡å·"""
    print('\nğŸ›‘ æ­£åœ¨åœæ­¢æœåŠ¡å™¨...')
    sys.exit(0)

def open_browser(port):
    """å»¶è¿Ÿæ‰“å¼€æµè§ˆå™¨"""
    time.sleep(1.5)
    webbrowser.open(f'http://localhost:{port}')

@app.route('/')
def index():
    return render_template("index.html")

@app.route('/generate-docs', methods=['POST'])
def generate_docs():
    try:
        if not doc_generator:
            return jsonify({'success': False, 'error': 'OpenAI APIå¯†é’¥æœªé…ç½®æˆ–æ— æ•ˆ'})
            
        data = request.get_json()
        filename = data.get('filename')
        content = data.get('content')
        lang = data.get('lang', 'zh')
        style = data.get('style', 'manual')
        is_batch = data.get('is_batch', False)

        if not filename or not content:
            return jsonify({'success': False, 'error': 'æ–‡ä»¶åå’Œå†…å®¹ä¸èƒ½ä¸ºç©º'})

        if is_batch:
            # æ‰¹é‡å¤„ç†æ¨¡å¼
            documentation = doc_generator.generate_batch_documentation(content, filename, lang, style)
        else:
            # å•æ–‡ä»¶å¤„ç†æ¨¡å¼
            documentation = doc_generator.generate_documentation(content, filename, lang, style)

        # ä¿å­˜ä¸º Markdown æ–‡ä»¶
        output_filename = f"{filename.replace('.zip', '')}_docs.md" if is_batch else "output.md"
        
        # åˆ›å»ºè¾“å‡ºç›®å½•
        os.makedirs('output', exist_ok=True)
        output_path = os.path.join('output', output_filename)
        
        with open(output_path, "w", encoding="utf-8") as f:
            f.write(documentation)

        return jsonify({
            'success': True,
            'documentation': documentation,
            'download': '/download-md',
            'filename': output_filename
        })

    except Exception as e:
        return jsonify({'success': False, 'error': str(e)})

@app.route('/process-zip', methods=['POST'])
def process_zip():
    try:
        if 'file' not in request.files:
            return jsonify({'success': False, 'error': 'æ²¡æœ‰ä¸Šä¼ æ–‡ä»¶'})
        
        file = request.files['file']
        if file.filename == '':
            return jsonify({'success': False, 'error': 'æ²¡æœ‰é€‰æ‹©æ–‡ä»¶'})

        # åˆ›å»ºä¸Šä¼ ç›®å½•
        os.makedirs('uploads', exist_ok=True)
        upload_path = os.path.join('uploads', file.filename)
        file.save(upload_path)

        # è§£æzipæ–‡ä»¶
        file_contents = extract_code_files(upload_path)
        
        # æ¸…ç†ä¸Šä¼ çš„æ–‡ä»¶
        os.remove(upload_path)

        if not file_contents:
            return jsonify({'success': False, 'error': 'å‹ç¼©åŒ…ä¸­æ²¡æœ‰æ‰¾åˆ°æ”¯æŒçš„ä»£ç æ–‡ä»¶'})

        return jsonify({
            'success': True,
            'file_contents': file_contents,
            'filename': file.filename
        })

    except Exception as e:
        return jsonify({'success': False, 'error': f'å¤„ç†å‹ç¼©åŒ…æ—¶å‡ºé”™: {str(e)}'})

def extract_code_files(zip_path):
    """ä»zipæ–‡ä»¶ä¸­æå–æ‰€æœ‰æ”¯æŒçš„ä»£ç æ–‡ä»¶"""
    file_contents = {}
    
    try:
        with zipfile.ZipFile(zip_path, 'r') as zip_ref:
            for file_info in zip_ref.filelist:
                # è·³è¿‡ç›®å½•å’Œéšè—æ–‡ä»¶
                if file_info.is_dir() or file_info.filename.startswith('.'):
                    continue
                
                # æ£€æŸ¥æ–‡ä»¶æ‰©å±•å
                file_path = Path(file_info.filename)
                if file_path.suffix.lower() in SUPPORTED_EXTENSIONS:
                    try:
                        # è¯»å–æ–‡ä»¶å†…å®¹
                        with zip_ref.open(file_info.filename) as file:
                            content = file.read().decode('utf-8', errors='ignore')
                            if content.strip():  # åªä¿å­˜éç©ºæ–‡ä»¶
                                file_contents[file_info.filename] = content
                    except Exception as e:
                        print(f"æ— æ³•è¯»å–æ–‡ä»¶ {file_info.filename}: {e}")
                        continue
    
    except Exception as e:
        raise Exception(f"æ— æ³•è§£æå‹ç¼©åŒ…: {e}")
    
    return file_contents

@app.route('/analyze-github', methods=['POST'])
def analyze_github():
    try:
        data = request.get_json()
        github_url = data.get('github_url', '').strip()
        
        if not github_url:
            return jsonify({'success': False, 'error': 'GitHub URLä¸èƒ½ä¸ºç©º'})
        
        # éªŒè¯å’Œè§„èŒƒåŒ–GitHub URL
        normalized_url = normalize_github_url(github_url)
        if not normalized_url:
            return jsonify({'success': False, 'error': 'æ— æ•ˆçš„GitHub URLæ ¼å¼'})
        
        # ä¸‹è½½å¹¶è§£æGitHubä»“åº“
        print(f"ğŸ“¥ æ­£åœ¨ä¸‹è½½GitHubä»“åº“: {normalized_url}")
        file_contents, repo_info = download_github_repo(normalized_url)
        
        if not file_contents:
            return jsonify({'success': False, 'error': 'GitHubä»“åº“ä¸­æ²¡æœ‰æ‰¾åˆ°æ”¯æŒçš„ä»£ç æ–‡ä»¶'})
        
        return jsonify({
            'success': True,
            'file_contents': file_contents,
            'repo_info': repo_info,
            'filename': f"{repo_info['name']}.github"
        })
        
    except requests.exceptions.RequestException as e:
        return jsonify({'success': False, 'error': f'ç½‘ç»œè¯·æ±‚å¤±è´¥: {str(e)}'})
    except Exception as e:
        return jsonify({'success': False, 'error': f'åˆ†æGitHubä»“åº“æ—¶å‡ºé”™: {str(e)}'})

def normalize_github_url(url):
    """è§„èŒƒåŒ–GitHub URL"""
    try:
        # ç§»é™¤å¤šä½™çš„ç©ºç™½å’Œæœ«å°¾çš„æ–œæ 
        url = url.strip().rstrip('/')
        
        # æ”¯æŒçš„GitHub URLæ ¼å¼
        patterns = [
            r'https://github\.com/([^/]+)/([^/]+)',  # æ ‡å‡†æ ¼å¼
            r'github\.com/([^/]+)/([^/]+)',          # æ²¡æœ‰https
            r'([^/]+)/([^/]+)',                      # åªæœ‰ç”¨æˆ·å/ä»“åº“å
        ]
        
        for pattern in patterns:
            match = re.match(pattern, url)
            if match:
                username, repo = match.groups()
                # ç§»é™¤.gitåç¼€
                repo = repo.replace('.git', '')
                return f"https://github.com/{username}/{repo}"
        
        return None
    except Exception:
        return None

def download_github_repo(github_url):
    """ä¸‹è½½GitHubä»“åº“å¹¶æå–ä»£ç æ–‡ä»¶"""
    try:
        # è§£æURLè·å–ç”¨æˆ·åå’Œä»“åº“å
        parts = github_url.replace('https://github.com/', '').split('/')
        if len(parts) < 2:
            raise Exception("æ— æ•ˆçš„GitHub URL")
        
        username, repo_name = parts[0], parts[1]
        
        # è·å–ä»“åº“ä¿¡æ¯
        api_url = f"https://api.github.com/repos/{username}/{repo_name}"
        repo_response = requests.get(api_url, timeout=10)
        
        if repo_response.status_code == 404:
            raise Exception("ä»“åº“ä¸å­˜åœ¨æˆ–ä¸ºç§æœ‰ä»“åº“")
        elif repo_response.status_code != 200:
            raise Exception(f"è·å–ä»“åº“ä¿¡æ¯å¤±è´¥: {repo_response.status_code}")
        
        repo_data = repo_response.json()
        
        # æ„å»ºä¸‹è½½URL
        download_url = f"https://github.com/{username}/{repo_name}/archive/refs/heads/main.zip"
        
        # å°è¯•mainåˆ†æ”¯ï¼Œå¦‚æœå¤±è´¥åˆ™å°è¯•masteråˆ†æ”¯
        response = requests.get(download_url, timeout=30, stream=True)
        if response.status_code != 200:
            download_url = f"https://github.com/{username}/{repo_name}/archive/refs/heads/master.zip"
            response = requests.get(download_url, timeout=30, stream=True)
        
        if response.status_code != 200:
            raise Exception(f"ä¸‹è½½ä»“åº“å¤±è´¥: HTTP {response.status_code}")
        
        # åˆ›å»ºä¸´æ—¶æ–‡ä»¶ä¿å­˜zip
        with tempfile.NamedTemporaryFile(delete=False, suffix='.zip') as temp_file:
            for chunk in response.iter_content(chunk_size=8192):
                temp_file.write(chunk)
            temp_zip_path = temp_file.name
        
        try:
            # è§£æzipæ–‡ä»¶
            file_contents = extract_code_files_from_github_zip(temp_zip_path, repo_name)
            
            # æ•´ç†ä»“åº“ä¿¡æ¯
            repo_info = {
                'name': repo_data.get('name', repo_name),
                'description': repo_data.get('description', ''),
                'language': repo_data.get('language', ''),
                'stars': repo_data.get('stargazers_count', 0),
                'forks': repo_data.get('forks_count', 0),
                'url': github_url,
                'size': repo_data.get('size', 0)
            }
            
            return file_contents, repo_info
            
        finally:
            # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
            os.unlink(temp_zip_path)
            
    except requests.exceptions.Timeout:
        raise Exception("ä¸‹è½½è¶…æ—¶ï¼Œè¯·æ£€æŸ¥ç½‘ç»œè¿æ¥æˆ–ç¨åé‡è¯•")
    except requests.exceptions.ConnectionError:
        raise Exception("ç½‘ç»œè¿æ¥å¤±è´¥ï¼Œè¯·æ£€æŸ¥ç½‘ç»œè®¾ç½®")
    except Exception as e:
        raise Exception(str(e))

def extract_code_files_from_github_zip(zip_path, repo_name):
    """ä»GitHubä¸‹è½½çš„zipæ–‡ä»¶ä¸­æå–ä»£ç æ–‡ä»¶"""
    file_contents = {}
    
    try:
        with zipfile.ZipFile(zip_path, 'r') as zip_ref:
            for file_info in zip_ref.filelist:
                # è·³è¿‡ç›®å½•
                if file_info.is_dir():
                    continue
                
                file_path = file_info.filename
                
                # GitHubçš„zipæ–‡ä»¶åŒ…å«ä¸€ä¸ªé¡¶çº§ç›®å½•ï¼Œéœ€è¦å»é™¤
                path_parts = file_path.split('/')
                if len(path_parts) <= 1:
                    continue
                
                # å»é™¤é¡¶çº§ç›®å½•ï¼ˆé€šå¸¸æ˜¯ reponame-main æˆ– reponame-masterï¼‰
                relative_path = '/'.join(path_parts[1:])
                
                # è·³è¿‡éšè—æ–‡ä»¶ã€node_modulesã€.gitç­‰ç›®å½•
                if should_skip_file(relative_path):
                    continue
                
                # æ£€æŸ¥æ–‡ä»¶æ‰©å±•å
                file_ext = Path(relative_path).suffix.lower()
                if file_ext in SUPPORTED_EXTENSIONS:
                    try:
                        with zip_ref.open(file_info.filename) as file:
                            content = file.read().decode('utf-8', errors='ignore')
                            if content.strip() and len(content) < 100000:  # é™åˆ¶æ–‡ä»¶å¤§å°
                                file_contents[relative_path] = content
                    except Exception as e:
                        print(f"æ— æ³•è¯»å–æ–‡ä»¶ {relative_path}: {e}")
                        continue
    
    except Exception as e:
        raise Exception(f"è§£æGitHubä»“åº“å¤±è´¥: {e}")
    
    return file_contents

def should_skip_file(file_path):
    """åˆ¤æ–­æ˜¯å¦åº”è¯¥è·³è¿‡æŸä¸ªæ–‡ä»¶"""
    skip_patterns = [
        'node_modules/', '.git/', '__pycache__/', '.pytest_cache/',
        'venv/', 'env/', '.env/', 'dist/', 'build/', 'target/',
        '.idea/', '.vscode/', '.DS_Store', 'Thumbs.db',
        'package-lock.json', 'yarn.lock', '.gitignore'
    ]
    
    # è·³è¿‡éšè—æ–‡ä»¶å’Œç›®å½•
    if file_path.startswith('.') or ('/.') in file_path:
        return True
    
    # è·³è¿‡ç‰¹å®šæ¨¡å¼
    for pattern in skip_patterns:
        if pattern in file_path:
            return True
    
    return False

@app.route('/download-md')
def download_markdown():
    try:
        output_path = os.path.join('output', 'output.md')
        if os.path.exists(output_path):
            return send_file(output_path, as_attachment=True)
        else:
            return jsonify({'error': 'æ–‡ä»¶ä¸å­˜åœ¨'}), 404
    except Exception as e:
        return jsonify({'error': str(e)}), 500

if __name__ == '__main__':
    # æ³¨å†Œä¿¡å·å¤„ç†å™¨
    signal.signal(signal.SIGINT, signal_handler)
    
    print("ğŸš€ æ™ºèƒ½ä»£ç æ–‡æ¡£ç”Ÿæˆç³»ç»Ÿå¯åŠ¨ä¸­...")
    
    # æ£€æŸ¥APIå¯†é’¥
    if not OPENAI_API_KEY or OPENAI_API_KEY == "your-api-key-here":
        print("âš ï¸  è­¦å‘Š: OpenAI APIå¯†é’¥æœªé…ç½®ï¼")
        print("è¯·è®¾ç½®ç¯å¢ƒå˜é‡ OPENAI_API_KEY æˆ–åœ¨ä»£ç ä¸­é…ç½®å¯†é’¥")
        print("ç¤ºä¾‹: export OPENAI_API_KEY='your-api-key-here'")
    
    # å°è¯•æ¸…ç†é»˜è®¤ç«¯å£
    default_port = 9003
    print(f"ğŸ” æ£€æŸ¥ç«¯å£ {default_port} æ˜¯å¦å¯ç”¨...")
    
    if kill_port_process(default_port):
        port = default_port
    else:
        # æŸ¥æ‰¾å¯ç”¨ç«¯å£
        try:
            port = find_free_port(default_port)
            if port != default_port:
                print(f"âš ï¸  ç«¯å£ {default_port} è¢«å ç”¨ï¼Œä½¿ç”¨ç«¯å£ {port}")
        except Exception as e:
            print(f"âŒ {e}")
            print("ğŸ’¡ è¯·æ‰‹åŠ¨æ¸…ç†ç«¯å£åé‡è¯•ï¼Œæˆ–é‡å¯ç»ˆç«¯")
            sys.exit(1)
    
    print(f"\nğŸŒ æœåŠ¡åœ°å€: http://localhost:{port}")
    print("ğŸ“‹ ä½¿ç”¨è¯´æ˜:")
    print("   1. ä¸Šä¼ ä»£ç æ–‡ä»¶ï¼ˆæ”¯æŒæ‹–æ‹½ï¼‰æˆ–ä¸Šä¼ é¡¹ç›®å‹ç¼©åŒ…")
    print("   2. é€‰æ‹©è¯­è¨€ä¸æƒ³è¦çš„é£æ ¼")
    print("   3. ç‚¹å‡»ç”Ÿæˆæ–‡æ¡£æŒ‰é’®")
    print("   4. ç­‰å¾…AIåˆ†æå¹¶ç”Ÿæˆæ–‡æ¡£")
    print("   5. å¤åˆ¶æˆ–ä¿å­˜ç”Ÿæˆçš„æ–‡æ¡£ï¼Œæ”¯æŒmdå’Œpdfæ–‡ä»¶å¯¼å‡ºæ ¼å¼")
    print(f"\nğŸ’¡ æç¤º: ä½¿ç”¨ Ctrl+C (ä¸æ˜¯ Ctrl+Z) æ¥æ­£ç¡®åœæ­¢æœåŠ¡å™¨")
    print("âš ï¸  æ³¨æ„: è¯·ç¡®ä¿æ‚¨çš„OpenAI APIå¯†é’¥æœ‰æ•ˆä¸”æœ‰è¶³å¤Ÿé¢åº¦")
    print("=" * 60)
    
    # åœ¨åå°çº¿ç¨‹ä¸­æ‰“å¼€æµè§ˆå™¨
    browser_thread = threading.Thread(target=open_browser, args=(port,))
    browser_thread.daemon = True
    browser_thread.start()
    
    try:
        # å¯åŠ¨Flaskåº”ç”¨
        app.run(debug=False, host='0.0.0.0', port=port, use_reloader=False)
    except KeyboardInterrupt:
        print('\nğŸ‘‹ æœåŠ¡å™¨å·²åœæ­¢')
    except Exception as e:
        print(f'\nâŒ æœåŠ¡å™¨å¯åŠ¨å¤±è´¥: {e}')
        sys.exit(1)